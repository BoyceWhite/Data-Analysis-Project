{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlTBAt6js-5Q"
   },
   "source": [
    "Before Presentation:\n",
    "* word cloud (Calvin)\n",
    "* word frequency table (positive and negative) (Calvin)\n",
    "* AI comparison (Chelsea & Boyce)\n",
    "* classification report visualization (Calvin)\n",
    "* PCA to get the most important features (Chelsea)\n",
    "* Hyperparameter performance (Boyce)\n",
    "* Decision Tree (Boyce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RESEQ8gus7cC"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9UOJtv7mtECo"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('TEST Dataset.csv')\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "reviews = data['review']\n",
    "sentiments = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UB-D5Lh-RwDV"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('TEST Dataset.csv')\n",
    "# Use a list to store reviews and sentiments from all chunks\n",
    "reviews_list = []\n",
    "sentiments_list = []\n",
    "\n",
    "# Iterate through the chunks\n",
    "for chunk in pd.read_csv('IMDB Dataset.csv', chunksize=1000, on_bad_lines='skip', engine='python'):\n",
    "    # Access the columns within each chunk and append to lists\n",
    "    reviews_list.extend(chunk['review'].tolist())\n",
    "    sentiments_list.extend(chunk['sentiment'].tolist())\n",
    "\n",
    "# Create dataframes from the lists\n",
    "reviews = pd.Series(reviews_list)\n",
    "sentiments = pd.Series(sentiments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y1RvC0nOtGOO"
   },
   "outputs": [],
   "source": [
    "#Removing Punctuation and printing an example\n",
    "# print(\"\\n PUNCTUATION INTACT: \\n\", reviews[0])\n",
    "reviews = reviews.str.lower().str.strip().str.translate(str.maketrans('', '', string.punctuation))\n",
    "# print(\"\\n PUNCTUATION REMOVED: \\n\", reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-IJKck4VtInQ"
   },
   "outputs": [],
   "source": [
    "#Creating Bag Of Words\n",
    "vectorizer = CountVectorizer(stop_words='english') #Removes some words like 'the' 'and' 'a'\n",
    "x = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QgfzGfktKwa",
    "outputId": "2fb9325d-9b6d-46dd-d1c0-8371b30a51a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.686\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.49      0.61      5044\n",
      "    positive       0.63      0.88      0.74      4956\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.72      0.69      0.67     10000\n",
      "weighted avg       0.72      0.69      0.67     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predictive Model\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, sentiments, test_size=0.2, random_state=1)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE6aMEJ0KyI7"
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-zMGwQxCOQL1"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 53.7 GiB for an array with shape (40000, 180082) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m      3\u001b[0m PCA \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m PCA\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m x_train_pca \u001b[38;5;241m=\u001b[39m PCA\u001b[38;5;241m.\u001b[39mtransform(x_train\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[0;32m      7\u001b[0m x_test_pca \u001b[38;5;241m=\u001b[39m PCA\u001b[38;5;241m.\u001b[39mtransform(x_test\u001b[38;5;241m.\u001b[39mtoarray())\n",
      "File \u001b[1;32mc:\\Users\\Chelsea\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Chelsea\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 53.7 GiB for an array with shape (40000, 180082) and data type int64"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCA = PCA(n_components=0.95)\n",
    "PCA.fit(x_train.toarray())\n",
    "\n",
    "x_train_pca = PCA.transform(x_train.toarray())\n",
    "x_test_pca = PCA.transform(x_test.toarray())\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "model.fit(x_train_pca, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_pca)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
